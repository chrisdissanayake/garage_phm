[
  {
    "objectID": "calibration.html#arduino",
    "href": "calibration.html#arduino",
    "title": "1  Calibration",
    "section": "1.1 Arduino",
    "text": "1.1 Arduino"
  },
  {
    "objectID": "calibration.html#python",
    "href": "calibration.html#python",
    "title": "1  Calibration",
    "section": "1.2 Python",
    "text": "1.2 Python"
  },
  {
    "objectID": "calibration.html#verify-adc",
    "href": "calibration.html#verify-adc",
    "title": "1  Calibration",
    "section": "1.2 Verify ADC",
    "text": "1.2 Verify ADC"
  },
  {
    "objectID": "calibration.html#axis",
    "href": "calibration.html#axis",
    "title": "1  Calibration",
    "section": "1.4 Axis",
    "text": "1.4 Axis"
  },
  {
    "objectID": "calibration.html#tilt-orientation",
    "href": "calibration.html#tilt-orientation",
    "title": "1  Calibration",
    "section": "1.5 Tilt Orientation",
    "text": "1.5 Tilt Orientation\nNeed to write the procedure.\n\npre_proc_tbl &lt;- function(file_name) {\n  d &lt;- read_table(str_glue(\"../data/{file_name}.txt\"), \n                  col_types = cols(.default = \"character\", \"X5\" = col_skip()),\n                  skip = 10)\n  col_names &lt;- c(\"time\", \"x\", \"y\", \"z\")\n  d &lt;- set_names(d, col_names)\n  \n  d &lt;- d |&gt; \n    mutate_if(is.character, .funs = as.numeric) |&gt; \n    mutate(time = as.numeric(time), \n           time = lubridate::milliseconds(time))  \n  \n  d &lt;- d |&gt; tidyr::drop_na()\n}\n\n\nd &lt;- pre_proc_tbl(\"garagedoor_home-1_bode\")\n\n\nimport numpy as np\nimport scipy.stats as ss\nfrom sklearn.metrics import mutual_info_score\n\ndef numBins(nObs, corr=None):\n    #optimal number of bins for discretization\n    if corr is None: #univariate case\n        z = (8+324*nObs+12*(36*nObs+729*nObs**2)**.5)**(1/3.)\n        b = round(z/6.+2./(3*z)+1./3)\n    else: #bivariate case\n        b = round(2**-.5*(1+(1+24*nObs/(1.-corr**2))**.5)**.5)\n    \n    return int(b)\n\ndef mutualInfor(x,y, norm=False):\n  #mutual information\n  bXY = numBins(x.shape[0], corr = np.corrcoef(x,y)[0,1])\n  cXY = np.histogram2d(x,y, bXY)[0]\n  iXY = mutual_info_score(None, None, contingency=cXY)\n  if norm:\n    hX = ss.entropy(np.histogram(x, bins)[0]) #marginal \n    hY = ss.entropy(np.histogram(y, bins)[0]) #marginal\n    iXY /= min(hX, hY) #normalized mutual information\n    \n  return iXY\n  \nx = r.d['x']\nx = np.array(x)\ny = r.d['y']\ny = np.array(y)\n\nbins=10 # descretize sample space\n\nnmi = mutualInfor(x,y,True)\ncorr = np.corrcoef(x,y)[0,1]\n\nd = {\"nmi\": nmi, \"corr\": corr}\nd\n\n#&gt; {'nmi': 0.19540919457977227, 'corr': -0.27134033163438037}\n\n\nmutual information is not a metric."
  },
  {
    "objectID": "preprocessing.html",
    "href": "preprocessing.html",
    "title": "3  Preprocessing Methods",
    "section": "",
    "text": "4 Signal Data\nThe function for initial data cleaning:\npre_proc_tbl &lt;- function(file_name) {\n  d &lt;- read_table(str_glue(\"../data/{file_name}.txt\"), \n                  col_types = cols(.default = \"character\", \"X6\" = col_skip()),\n                  skip = 10)\n  col_names &lt;- c(\"time\", \"x\", \"y\", \"z\", \"tilt_fc\", \"tilt_tw\")\n  d &lt;- set_names(d, col_names)\n  \n  d &lt;- d |&gt; \n    mutate_if(is.character, .funs = as.numeric) |&gt; \n    mutate(time = as.numeric(time), \n           time = lubridate::milliseconds(time)) # for modeling, not for plotting \n  \n  d &lt;- d |&gt; tidyr::drop_na()\n}\nThe function to plot the signal:\nplot_ad &lt;- function(tbl) {\n  tbl |&gt; \n    pivot_longer(c(\"x\", \"y\", \"z\")) |&gt; \n    mutate(time = seq_along(time)/1000) |&gt; # in ms\n    ggplot(aes(time, value)) +\n    geom_point(size = 0.1) +\n    geom_line(alpha = 0.3) +\n    facet_wrap(~name) +\n    labs(x = \"time (s)\", \n         y = \"Acceleration (g)\")\n}\nHere is what a signal looks like for one complete cycle (please look at the landing page for the definition).\nd &lt;- pre_proc_tbl(\"2023-06-10_garagedoor-1\") \n\nd |&gt; \n  plot_ad() +\n  labs(title = \"Accelerometer Signal (Triaxial)\")\nThe data has irregular spike patterns caused by the movement of the curved door arm. These serve no purpose other than to contaminate the signal, and therefore are removed using a simple filter.\nBelow is an automated procedure that cleans and segments the signal into “explainable” parts. It is easy to visualize the idle, torsion coil, and impulse responses from the signal.\nd &lt;- d |&gt; \n  mutate(z_smo = loess(z ~ time, span = 0.1)$fitted, \n         y_smo = loess(y ~ time, span = 0.1)$fitted) \n\nts_data &lt;- d |&gt; pull(z_smo) |&gt; ts()\n\nd |&gt; \n  pivot_longer(c(z, z_smo, y, y_smo)) |&gt; \n  ggplot(aes(time, value)) +\n  geom_point(size = 0.5) +\n  facet_wrap(~name) +\n  labs(title = \"Smoothed Signal\")"
  },
  {
    "objectID": "preprocessing.html#extract-orthogonal-locations",
    "href": "preprocessing.html#extract-orthogonal-locations",
    "title": "3  Preprocessing Methods",
    "section": "6.1 Extract Orthogonal Locations",
    "text": "6.1 Extract Orthogonal Locations\nI am using a machine learning method here to isolate the up and down slopes, which are the torsion coil unwinding and winding scenarios. Orthogonal here means that the garage door’s orientation to the ground, horizontal or vertical.\n\nimport statsmodels.api as sm1\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\nfrom sklearn import linear_model, datasets\n\n# Return the t-statistic for a given parameter estimate.\ndef tValLinR(close):\n    # tValue from a linear trend\n    x = np.ones((close.shape[0], 2))\n    x[:, 1] = np.arange(close.shape[0])\n    ols = sm1.OLS(close, x).fit()\n    return ols.tvalues[1]\n\n\ndef getBinsFromTrend(molecule, close, span):\n    '''\n    Derive labels from the sign of t-value of trend line\n    output includes:\n      - t1: End time for the identified trend\n      - tVal: t-value associated with the estimated trend coefficient\n      - bin: Sign of the trend\n    The t-statistics for each tick has a different look-back window.\n\n    - idx start time in look-forward window\n    - dt1 stop time in look-forward window\n    - df1 is the look-forward window\n    - iloc ?\n    '''\n    out = pd.DataFrame(index=molecule, columns=['t1', 'tVal', 'bin', 'windowSize'])\n    hrzns = range(*span)\n    windowSize = span[1] - span[0]\n    maxWindow = span[1] - 1\n    minWindow = span[0]\n    for idx in close.index:\n        idx += maxWindow\n        if idx &gt;= len(close):\n            break\n        df_tval = pd.Series(dtype='float64')\n        iloc0 = close.index.get_loc(idx)\n        # if iloc0+max(hrzns) &gt; close.shape[0]:\n        #    continue\n        for hrzn in hrzns:\n            dt1 = close.index[iloc0 - hrzn + 1]\n            df1 = close.loc[dt1:idx]\n            df_tval.loc[dt1] = tValLinR(df1.values)  # calculates t-statistics on period\n            dt1 = df_tval.replace([-np.inf, np.inf, np.nan],\n                              0).abs().idxmax()  # get largest t-statistics calculated over span period\n\n        # print(df_tval.index[-1])\n        # print(dt1)\n        # print(abs(df_tval.values).argmax() + minWindow)\n        out.loc[idx, ['t1', 'tVal', 'bin', 'windowSize']] = df_tval.index[-1], df_tval[dt1], np.sign(df_tval[dt1]), abs(\n            df_tval.values).argmax() + minWindow  # prevent leakage\n    out['t1'] = pd.to_datetime(out['t1'])\n    out['bin'] = pd.to_numeric(out['bin'], downcast='signed')\n\n    # deal with massive t-Value outliers - they dont provide more confidence and they ruin the scatter plot\n    tValueVariance = out['tVal'].values.var()\n    tMax = 20\n    if tValueVariance &lt; tMax:\n        tMax = tValueVariance\n\n    out.loc[out['tVal'] &gt; tMax, 'tVal'] = tMax  # cutoff tValues &gt; 20\n    out.loc[out['tVal'] &lt; (-1) * tMax, 'tVal'] = (-1) * tMax  # cutoff tValues &lt; -20\n    return out.dropna(subset=['bin'])\n\n\n\nidx_range_from = 5\nidx_range_to = 10\ndf0 = pd.Series(r.ts_data)\n\nspan = [idx_range_from,idx_range_to,1] # [3,10,1] = range(3,10)\n\ndf1 = getBinsFromTrend(df0.index, df0, span) \ntValues = df1['tVal'].values\n\n\nlibrary(reticulate)\n\nd_f &lt;- py$df1 |&gt; \n  rownames_to_column(\"id\") |&gt; \n  unnest(tVal) \n\nd_fmerg &lt;- d |&gt; \n  rownames_to_column(\"id\") |&gt; \n  left_join(d_f) |&gt;\n  tidyr::fill(bin, .direction = \"downup\") |&gt; \n  mutate(id = as.numeric(id)) |&gt; \n  na.omit() |&gt; \n  mutate(run_id = consecutive_id(bin)) |&gt; \n  group_by(run_id) |&gt; \n  mutate(bin = ifelse(n() &lt; 1000, 0, bin))\n\nd_fmerg |&gt; \n  ggplot(aes(id, z, col = as.factor(bin))) +\n  geom_point(size = 0.3) +\n  labs(x = \"time (s)\", \n       y = \"Calibrated Value\", \n       col = \"Recipe Step\")\n\n\n\n\nThis works for other examples as well.\nHere is the nomenclature:\n\n0 = horizontal or vertical position\n-1 = torsion coil winding\n1 = torsion coil unwinding"
  },
  {
    "objectID": "preprocessing.html#extract-door-idle-locations",
    "href": "preprocessing.html#extract-door-idle-locations",
    "title": "3  Preprocessing Methods",
    "section": "6.2 Extract Door Idle Locations",
    "text": "6.2 Extract Door Idle Locations\nThe door can be idle in orthogonal locations, and I am fitting a simple dependent mixture model here.\n\nlibrary(depmixS4)\n\nset.seed(123)\n\nhmm_model &lt;- depmixS4::depmix(data = d_fmerg, nstates = 2, z_smo~z)\nhmm_fit &lt;- fit(hmm_model)\n\n#&gt; converged at iteration 36 with logLik: 24001\n\n# hmm_fit@transition\n\n# plot(ts(posterior(hmm_fit, type = \"smoothing\")), ylab = \"probability\", frame = FALSE)"
  },
  {
    "objectID": "preprocessing.html#results",
    "href": "preprocessing.html#results",
    "title": "3  Preprocessing Methods",
    "section": "6.3 Results",
    "text": "6.3 Results\n\nd_fmerg_final &lt;- d_fmerg |&gt; \n  ungroup() |&gt; \n  bind_cols(smo_prob = posterior(hmm_fit, type = \"smoothing\")[,1]) |&gt; \n  mutate(bin_hmm = ifelse(smo_prob &gt; 0.999, \"transition\", \"idle\")) |&gt; \n  mutate(run_idle_id = consecutive_id(bin_hmm)) |&gt; \n  group_by(run_idle_id) |&gt; \n  mutate(numbers = n(),\n         bin_hmm = ifelse(n() &lt; 200 , \"transition\", bin_hmm)) |&gt; \n  mutate(recipe_step = paste(bin_hmm, bin))\n\n\nd_fmerg_final |&gt;\n  pivot_longer(c(x, y, z)) |&gt;\n  ggplot(aes(time, value, col = as.factor(recipe_step))) +\n  geom_point(size = 0.3) +\n  facet_wrap(~name) +\n  labs(x = \"time (s)\",\n       y = \"Calibrated Value\",\n       col = \"recipe step\")\n\n\n\n\nPerfect!"
  },
  {
    "objectID": "datacollection.html",
    "href": "datacollection.html",
    "title": "2  Query Data",
    "section": "",
    "text": "Data is stored in two AWS RDS databases. Please let me know if you have lost the credentials.\n\ngd_phm_status : This has the model output information, hardware maintenance information, versioning, and configuration settings.\nmetrics : This hosts accuracy and reliability metrics for other all my projects. The table for this project is called “gd_phm”.\n\nShown below is a generic sequence.\nMake a connection:\n\ncon &lt;- dbConnect(\n  RPostgres::Postgres(),\n  dbname = \"gd_phm_status\",\n  host = Sys.getenv(\"gd_db_host\"),\n  port = 5432,\n  user = Sys.getenv(\"gd_db_user\"),\n  password = Sys.getenv(\"gd_db_pw\")\n)\n\nGet all relevant table names:\n\ntbl &lt;- DBI::dbGetQuery(\n  conn = con,\n  \"SELECT table_name\n  FROM information_schema.tables\n  WHERE table_name like '%gd%'\n\"\n)\n\ntbl |&gt; pull(table_name) |&gt; cat(sep = \", \")\n\n#&gt; gd_meas_tbl, gd_config_hw_tbl, gd_config_models_tbl\n\n\nPull data:\n\ntbl &lt;- DBI::dbGetQuery(\n  conn = con,\n  \n  \"WITH joined_tbl AS (\n    SELECT\n      gd_config_hw_tbl.*,\n      meas_date,\n      meas_seq,\n      status,\n      gd_meas_tbl.model AS model,\n      prob,\n      model_version,\n      version_from,\n      version_to\n    FROM gd_config_hw_tbl\n    INNER JOIN gd_meas_tbl\n      ON (gd_config_hw_tbl.location_id = gd_meas_tbl.location_id)\n    INNER JOIN gd_config_models_tbl\n      ON (\n        gd_config_hw_tbl.location_id = gd_config_models_tbl.location_id AND\n        gd_meas_tbl.model = gd_config_models_tbl.model\n         )\n    )\n  \n  SELECT\n    state,\n    city_code,\n    location_id,\n    model,\n    model_version,\n    meas_date,\n    MAX(prob) AS prob_max\n  FROM joined_tbl\n  WHERE (meas_date &gt;= version_from AND ((version_to IS NULL) OR meas_date &lt;= version_to))\n  GROUP BY state, city_code, location_id, model, model_version, meas_date;\"\n)\n\ntbl |&gt; head(10)\n\n#&gt;    state city_code location_id    model model_version  meas_date  prob_max\n#&gt; 1     MN       AAA      A00.01 arm_brkt    2023.03.12 2023-03-12 0.0008547\n#&gt; 2     MN       AAA      A00.01 arm_brkt    2023.03.12 2023-03-13 0.0014096\n#&gt; 3     MN       AAA      A00.01 arm_brkt    2023.03.12 2023-03-14 0.0009876\n#&gt; 4     MN       AAA      A00.01 arm_brkt    2023.03.12 2023-03-15 0.0023421\n#&gt; 5     MN       AAA      A00.01 arm_brkt    2023.03.15 2023-03-15 0.0023421\n#&gt; 6     MN       AAA      A00.01 arm_brkt    2023.03.15 2023-03-16 0.0069242\n#&gt; 7     MN       AAA      A00.01 arm_brkt    2023.03.15 2023-03-17 0.0062839\n#&gt; 8     MN       AAA      A00.01 arm_brkt    2023.03.15 2023-03-18 0.0352436\n#&gt; 9     MN       AAA      A00.01 arm_brkt    2023.03.15 2023-03-19 0.0210955\n#&gt; 10    MN       AAA      A00.01 arm_brkt    2023.03.15 2023-03-20 0.0015077\n\n\nMake a plot:\n\ntbl |&gt; \n  filter(meas_date &lt; as.Date(\"2023-06-11\")) |&gt; \n  mutate(model = ifelse(model == \"arm_brkt\", \"Arm Bracket Fault\", model)) |&gt; \n  ggplot(aes(meas_date, prob_max, col = model_version)) +\n  geom_point() +\n  facet_grid(location_id~ model, scales = \"free\") +\n  scale_x_date(date_breaks = \"2 weeks\") +\n  labs(\n    title = \"Daily Maximum Fault Probability for Each IoT Device Monitored Against Model Version\", \n    x = \"Date\", \n    y = \"Fault Probability\",\n    col = \"Model Version\"\n      )\n\n\n\n\nImportant! Please close the connection after you are done.\n\ndbDisconnect(con)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Garage Door Prognostics and Health Management",
    "section": "",
    "text": "Introduction\nWork in Progress\nWelcome to the documentation for the “Garage Door Prognostics” project.\nThe sections are arranged by functionality."
  },
  {
    "objectID": "index.html#note-on-code-folding",
    "href": "index.html#note-on-code-folding",
    "title": "Garage Door Prognostics and Health Management",
    "section": "Note on Code Folding",
    "text": "Note on Code Folding\nI will leave the code blocks open by default, but there will be instances where code folding would warrant. If this is the case, you could easily unfold them by clicking an arrow above the output.\nHere is an example:\n\n\nCode\nmtcars |&gt; \n  ggplot(aes(disp, mpg, col = factor(cyl))) +\n  geom_point() +\n  labs(title = \"mpg vs dispacement\", \n       col = \"number of cylinders\")"
  },
  {
    "objectID": "index.html#session-information",
    "href": "index.html#session-information",
    "title": "Garage Door Prognostics and Health Management",
    "section": "Session Information",
    "text": "Session Information\nR info: R version 4.3.1 (2023-06-16) using the following packages: data.table (1.14.8, CRAN), ggforce (0.4.1, CRAN), gridExtra (2.3, CRAN), hht (2.1.6, CRAN), Hmisc (5.1-0, CRAN), janitor (2.2.0, CRAN), lubridate (1.9.2, CRAN), MSwM (1.5, CRAN), patchwork (1.1.2, CRAN), plotly (4.10.1, CRAN), scales (1.2.1, CRAN), tidyverse (2.0.0, CRAN), and zoo (1.8-12, CRAN).\nRust info: rustc 1.68.2 (9eb3afe9e 2023-03-27)\nPython info: Python 3.9.13 using the following packages: (_ipyw_jlab_nb_ext_conf0.1.0), (_libgcc_mutex0.1), (_openmp_mutex5.1), (alabaster0.7.12), (anaconda2022.10), (anaconda-client1.11.0), (anaconda-navigator2.3.2), (anaconda-project0.11.1), (anyio3.5.0), (appdirs1.4.4), (argon2-cffi21.3.0), (argon2-cffi-bindings21.2.0), (arrow1.2.2), (astroid2.11.7), (astropy5.1), (atomicwrites1.4.0), (attrs21.4.0), (automat20.2.0), (autopep81.6.0), (babel2.9.1), (backcall0.2.0), (backports1.1), (backports.functools_lru_cache1.6.4), (backports.tempfile1.0), (backports.weakref1.0.post1), (bcrypt3.2.0), (beautifulsoup44.11.1), (binaryornot0.4.4), (bitarray2.5.1), (bkcharts0.2), (black22.6.0), (blas1.0), (bleach4.1.0), (blosc1.21.0), (bokeh2.4.3), (boto31.24.28), (botocore1.27.28), (bottleneck1.3.5), (brotli1.0.9), (brotli-bin1.0.9), (brotlipy0.7.0), (brunsli0.1), (bzip21.0.8), (c-ares1.18.1), (ca-certificates2022.07.19), (certifi2022.9.14), (cffi1.15.1), (cfitsio3.470), (chardet4.0.0), (charls2.2.0), (charset-normalizer2.0.4), (click8.0.4), (cloudpickle2.0.0), (clyent1.2.2), (colorama0.4.5), (colorcet3.0.0), (conda23.1.0), (conda-build3.22.0), (conda-content-trust0.1.3), (conda-env2.6.0), (conda-pack0.6.0), (conda-package-handling1.9.0), (conda-repo-cli1.0.20), (conda-token0.4.0), (conda-verify3.4.2), (constantly15.1.0), (cookiecutter1.7.3), (cryptography37.0.1), (cssselect1.1.0), (curl7.84.0), (cycler0.11.0), (cython0.29.32), (cytoolz0.11.0), (daal4py2021.6.0), (dal2021.6.0), (dask2022.7.0), (dask-core2022.7.0), (dataclasses0.8), (datashader0.14.1), (datashape0.5.4), (dbus1.13.18), (debugpy1.5.1), (decorator5.1.1), (defusedxml0.7.1), (diff-match-patch20200713), (dill0.3.4), (distributed2022.7.0), (docutils0.18.1), (entrypoints0.4), (et_xmlfile1.1.0), (expat2.4.9), (fftw3.3.9), (filelock3.6.0), (flake84.0.1), (flask1.1.2), (fontconfig2.13.1), (fonttools4.25.0), (freetype2.11.0), (fsspec2022.7.1), (future0.18.2), (gensim4.1.2), (giflib5.2.1), (glib2.69.1), (glob20.7), (gmp6.2.1), (gmpy22.1.2), (greenlet1.1.1), (gst-plugins-base1.14.0), (gstreamer1.14.0), (h5py3.7.0), (hdf51.10.6), (heapdict1.0.1), (holoviews1.15.0), (hvplot0.8.0), (hyperlink21.0.0), (icu58.2), (idna3.3), (imagecodecs2021.8.26), (imageio2.19.3), (imagesize1.4.1), (importlib-metadata4.11.3), (importlib_metadata4.11.3), (incremental21.3.0), (inflection0.5.1), (iniconfig1.1.1), (intake0.6.5), (intel-openmp2021.4.0), (intervaltree3.1.0), (ipykernel6.15.2), (ipython7.31.1), (ipython_genutils0.2.0), (ipywidgets7.6.5), (isort5.9.3), (itemadapter0.3.0), (itemloaders1.0.4), (itsdangerous2.0.1), (jdcal1.4.1), (jedi0.18.1), (jeepney0.7.1), (jellyfish0.9.0), (jinja22.11.3), (jinja2-time0.2.0), (jmespath0.10.0), (joblib1.1.0), (jpeg9e), (jq1.6), (json50.9.6), (jsonschema4.16.0), (jupyter1.0.0), (jupyter_client7.3.4), (jupyter_console6.4.3), (jupyter_core4.11.1), (jupyter_server1.18.1), (jupyterlab3.4.4), (jupyterlab_pygments0.1.2), (jupyterlab_server2.10.3), (jupyterlab_widgets1.0.0), (jxrlib1.1), (keyring23.4.0), (kiwisolver1.4.2), (krb51.19.2), (lazy-object-proxy1.6.0), (lcms22.12), (ld_impl_linux-642.38), (lerc3.0), (libaec1.0.4), (libarchive3.6.1), (libbrotlicommon1.0.9), (libbrotlidec1.0.9), (libbrotlienc1.0.9), (libclang10.0.1), (libcurl7.84.0), (libdeflate1.8), (libedit3.1.20210910), (libev4.33), (libevent2.1.12), (libffi3.3), (libgcc-ng11.2.0), (libgfortran-ng11.2.0), (libgfortran511.2.0), (libgomp11.2.0), (libidn22.3.2), (liblief0.11.5), (libllvm1010.0.1), (libllvm1111.1.0), (libnghttp21.46.0), (libpng1.6.37), (libpq12.9), (libsodium1.0.18), (libspatialindex1.9.3), (libssh21.10.0), (libstdcxx-ng11.2.0), (libtiff4.4.0), (libunistring0.9.10), (libuuid1.0.3), (libwebp1.2.2), (libwebp-base1.2.2), (libxcb1.15), (libxkbcommon1.0.1), (libxml22.9.14), (libxslt1.1.35), (libzopfli1.0.3), (llvmlite0.38.0), (locket1.0.0), (lxml4.9.1), (lz43.1.3), (lz4-c1.9.3), (lzo2.10), (markdown3.3.4), (markupsafe2.0.1), (matplotlib3.5.2), (matplotlib-base3.5.2), (matplotlib-inline0.1.6), (mccabe0.7.0), (mistune0.8.4), (mkl2021.4.0), (mkl-service2.4.0), (mkl_fft1.3.1), (mkl_random1.2.2), (mock4.0.3), (mpc1.1.0), (mpfr4.0.2), (mpi1.0), (mpich3.3.2), (mpmath1.2.1), (msgpack-python1.0.3), (multipledispatch0.6.0), (munkres1.1.4), (mypy_extensions0.4.3), (navigator-updater0.3.0), (nbclassic0.3.5), (nbclient0.5.13), (nbconvert6.4.4), (nbformat5.5.0), (ncurses6.3), (nest-asyncio1.5.5), (networkx2.8.4), (nltk3.7), (nose1.3.7), (notebook6.4.12), (nspr4.33), (nss3.74), (numba0.55.1), (numexpr2.8.3), (numpy1.21.5), (numpy-base1.21.5), (numpydoc1.4.0), (olefile0.46), (oniguruma6.9.7.1), (openjpeg2.4.0), (openpyxl3.0.10), (openssl1.1.1q), (packaging21.3), (pandas1.4.4), (pandocfilters1.5.0), (panel0.13.1), (param1.12.0), (parsel1.6.0), (parso0.8.3), (partd1.2.0), (patch2.7.6), (patchelf0.13), (pathlib1.0.1), (pathspec0.9.0), (patsy0.5.2), (pcre8.45), (pep81.7.1), (pexpect4.8.0), (pickleshare0.7.5), (pillow9.2.0), (pip22.2.2), (pkginfo1.8.2), (platformdirs2.5.2), (plotly5.9.0), (pluggy1.0.0), (ply3.11), (poyo0.5.0), (prometheus_client0.14.1), (prompt-toolkit3.0.20), (prompt_toolkit3.0.20), (protego0.1.16), (psutil5.9.0), (ptyprocess0.7.0), (py1.11.0), (py-lief0.11.5), (pyasn10.4.8), (pyasn1-modules0.2.8), (pycodestyle2.8.0), (pycosat0.6.3), (pycparser2.21), (pyct0.4.8), (pycurl7.45.1), (pydispatcher2.0.5), (pydocstyle6.1.1), (pyerfa2.0.0), (pyflakes2.4.0), (pygments2.11.2), (pyhamcrest2.0.2), (pyjwt2.4.0), (pylint2.14.5), (pyls-spyder0.4.0), (pyodbc4.0.34), (pyopenssl22.0.0), (pyparsing3.0.9), (pyqt5.15.7), (pyqt5-sip12.11.0), (pyqtwebengine5.15.7), (pyrsistent0.18.0), (pysocks1.7.1), (pytables3.6.1), (pytest7.1.2), (python3.9.13), (python-dateutil2.8.2), (python-fastjsonschema2.16.2), (python-libarchive-c2.9), (python-lsp-black1.2.1), (python-lsp-jsonrpc1.0.0), (python-lsp-server1.5.0), (python-slugify5.0.2), (python-snappy0.6.0), (pytz2022.1), (pyviz_comms2.0.2), (pywavelets1.3.0), (pyxdg0.27), (pyyaml6.0), (pyzmq23.2.0), (qdarkstyle3.0.2), (qstylizer0.1.10), (qt5.15.9), (qt-main5.15.2), (qt-webengine5.15.9), (qtawesome1.0.3), (qtconsole5.3.2), (qtpy2.2.0), (qtwebkit5.212), (queuelib1.5.0), (readline8.1.2), (regex2022.7.9), (requests2.28.1), (requests-file1.5.1), (ripgrep13.0.0), (rope0.22.0), (rtree0.9.7), (ruamel.yaml0.17.21), (ruamel.yaml.clib0.2.6), (ruamel_yaml0.15.100), (s3transfer0.6.0), (scikit-image0.19.2), (scikit-learn1.0.2), (scikit-learn-intelex2021.6.0), (scipy1.9.1), (scrapy2.6.2), (seaborn0.11.2), (secretstorage3.3.1), (send2trash1.8.0), (service_identity18.1.0), (setuptools63.4.1), (sip6.6.2), (six1.16.0), (sklearn0.0.post4), (smart_open5.2.1), (snappy1.1.9), (sniffio1.2.0), (snowballstemmer2.2.0), (sortedcollections2.1.0), (sortedcontainers2.4.0), (soupsieve2.3.1), (sphinx5.0.2), (sphinxcontrib-applehelp1.0.2), (sphinxcontrib-devhelp1.0.2), (sphinxcontrib-htmlhelp2.0.0), (sphinxcontrib-jsmath1.0.1), (sphinxcontrib-qthelp1.0.3), (sphinxcontrib-serializinghtml1.1.5), (spyder5.3.3), (spyder-kernels2.3.3), (sqlalchemy1.4.39), (sqlite3.39.3), (statsmodels0.13.2), (sympy1.10.1), (tabulate0.8.10), (tbb2021.6.0), (tbb4py2021.6.0), (tblib1.7.0), (tenacity8.0.1), (terminado0.13.1), (testpath0.6.0), (text-unidecode1.3), (textdistance4.2.1), (threadpoolctl2.2.0), (three-merge0.1.1), (tifffile2021.7.2), (tinycss0.4), (tk8.6.12), (tldextract3.2.0), (toml0.10.2), (tomli2.0.1), (tomlkit0.11.1), (toolz0.11.2), (tornado6.1), (tqdm4.64.1), (traitlets5.1.1), (twisted22.2.0), (typing-extensions4.3.0), (typing_extensions4.3.0), (tzdata2022c), (ujson5.4.0), (unidecode1.2.0), (unixodbc2.3.11), (urllib31.26.11), (w3lib1.21.0), (watchdog2.1.6), (wcwidth0.2.5), (webencodings0.5.1), (websocket-client0.58.0), (werkzeug2.0.3), (wget1.21.3), (whatthepatch1.0.2), (wheel0.37.1), (widgetsnbextension3.5.2), (wrapt1.14.1), (wurlitzer3.0.2), (xarray0.20.1), (xlrd2.0.1), (xlsxwriter3.0.3), (xz5.2.6), (yaml0.2.5), (yapf0.31.0), (zeromq4.3.4), (zfp0.5.5), (zict2.1.0), (zipp3.8.0), (zlib1.2.12), (zope1.0), (zope.interface5.4.0), (zstd1.5.2)."
  },
  {
    "objectID": "index.html#how-this-is-organized",
    "href": "index.html#how-this-is-organized",
    "title": "Garage Door Prognostics and Health Management",
    "section": "How this is organized",
    "text": "How this is organized\nArranged by function to assist troubleshooting."
  },
  {
    "objectID": "index.html#system-configuration",
    "href": "index.html#system-configuration",
    "title": "Garage Door Prognostics and Health Management",
    "section": "System Configuration",
    "text": "System Configuration\n\n\n\n\n\n\n\n\n\ngraph TB\nA(Accelerometer)--&gt;AA \n\nsubgraph Replace\nAA[Arduino]--&gt;E[Thin Client]\nstyle Replace fill:#f0f0f0,stroke:grey,stroke-width:2px\nend\n\nE--&gt;F[AWS RDS]\nF--&gt;G(Dashboard &lt;/br&gt;Metrics, Sensor, Data Decisions)\nF--&gt;H[Decision Making]\nH--&gt;G\nGD(Garage Door) -.-&gt; A\nM(Calibration) -.-&gt; A\nstyle A fill:#B6E6E6\nstyle GD fill:salmon \nstyle E stroke:blue,stroke-width:3px\n\nsubgraph Thin-Client\nBB((Every &lt;/br&gt; 2 Hours))--&gt;CA[Gather Data]\nCA--&gt;CAA\nBB--&gt;CAA[Preprocess]\nCAA--&gt;CAAB{Door Activity?}\nCAAB--Yes--&gt;CBB[Run Models]\nCAAB--No--&gt;CAAC(End)\nCBB--&gt;CB[Data / Results]\nstyle BB fill:salmon \nstyle Thin-Client fill:#f0f0f0,stroke:blue,stroke-width:3px\nend"
  },
  {
    "objectID": "calibration.html#adxl335",
    "href": "calibration.html#adxl335",
    "title": "2  Calibration",
    "section": "2.1 ADXL335",
    "text": "2.1 ADXL335\nThe ADXL335 is a triaxial accelerometer with three analog outputs that correspond to the orthogonal X, Y, and Z axes. The accelerometer responds to tilt, and since it is mounted in parallel to the door (reference), this measurement translates to a dynamic angle of incline.\nThe technical datasheet for ADXL335 is here."
  },
  {
    "objectID": "calibration.html#preliminary-calibration",
    "href": "calibration.html#preliminary-calibration",
    "title": "2  Calibration",
    "section": "2.2 Preliminary Calibration",
    "text": "2.2 Preliminary Calibration\nThe calibration procedure is highlighted here. This also serves the purpose of verifying the functionality of the accelerometer.\n\n#include &lt;math.h&gt;\nconst int x_out = A0; \nconst int y_out = A1; \nconst int z_out = A2; \n\nunsigned long tms;\n\nvoid setup() {\n  Serial.begin(115200); \n}\n\nvoid loop() {\n  int x_adc_value, y_adc_value, z_adc_value; \n  \n  x_adc_value = analogRead(x_out);  \n  y_adc_value = analogRead(y_out);  \n  z_adc_value = analogRead(z_out);  \n\n//  Serial.print(\"x = \");\n//  Serial.print(x_adc_value);\n//  Serial.print(\"\\t\\t\");\n//  Serial.print(\"y = \");\n//  Serial.print(y_adc_value);\n//  Serial.print(\"\\t\\t\");\n//  Serial.print(\"z = \");\n//  Serial.print(z_adc_value);\n//  Serial.println(\"\\t\\t\");\n\n// Right hand rule is constrained\n\n  int x = map(x_adc_value, 264, 396, -100, 100);\n  float xg = (float)x/(-100.00);\n  \n  int y = map(y_adc_value, 267, 400, -100, 100);\n  float yg = (float)y/(-100.00);\n\n  int z = map(z_adc_value, 275, 410, -100, 100);\n  float zg = (float)z/(-100.00);\n\n\n// CW is positive\n\ndouble tilt_fc, tilt_tw;\n\n//  tilt_X =atan2(-yg,-zg)*57.2957795; /* yaw dof cannot be measured */ \n  tilt_fc = -1*atan2(xg,yg)*57.2957795; /* across the face of the door */\n  tilt_tw = -1*atan2(zg,yg)*57.2957795; /* towards and back */\n  \n\n  tms = millis();\n\n  Serial.print(tms); \n  Serial.print(\"\\t\");\n  Serial.print(xg);\n  Serial.print(\"\\t\");\n  Serial.print(yg);\n  Serial.print(\"\\t\");\n  Serial.print(zg);\n  Serial.print(\"\\t\");\n  Serial.print(tilt_fc);\n  Serial.print(\"\\t\");\n  Serial.print(tilt_tw);\n  Serial.print(\"\\n\");\n  \n//  delay(1000);\n\n}"
  },
  {
    "objectID": "calibration.html#tilt-orientation-calibration",
    "href": "calibration.html#tilt-orientation-calibration",
    "title": "2  Calibration",
    "section": "2.3 Tilt Orientation Calibration",
    "text": "2.3 Tilt Orientation Calibration\nThe door moves is relative to the left and right tracks, and this can cause many problems if the accelerometer is not positioned correctly.\n\n2.3.1 Install Adjustable Mount\nThe accelerometer mount is adjustable, and can be installed closer to the arm bracket, the closer the better. The reference tilt angle (tilt_fc) can be adjusted by loosening the M3 screws.\n\n\n \n\n\nHere are three outputs for three angles, -17 deg (CCW), 0 deg, and 17 deg (CW).\n\np_1 &lt;- pre_proc_tbl(\"angle-ccw17\") |&gt; \n  plot_ad() +\n  labs(title = \"-17 deg\") +\n  theme(axis.title = element_blank())\n\np_2 &lt;- pre_proc_tbl(\"2023-06-10_garagedoor-1\") |&gt; \n  plot_ad() +\n  labs(title = \"0 deg\") +\n  theme(axis.title = element_blank())\n\np_3 &lt;- pre_proc_tbl(\"angle-cw17\") |&gt; \n  plot_ad() +\n  labs(title = \"+17 deg\") +\n  theme(axis.title = element_blank())\n\np &lt;- p_1 /p_2/ p_3 \n\ngt &lt;- patchwork::patchworkGrob(p)\ngridExtra::grid.arrange(gt, left = \"Acceleration (g)\", bottom = \"time (s)\")\n\n\n\n\n\n\n2.3.2 Run Algorithm\nThe following procedure is a solution to this problem, proposed to exploit the nonlinear dependence between sensor variables, namely x-y and x-z. The solution also works without any preprocessing, which is also an advantage.\nBelow is an example calculation for the mutual information between x and y for the signal at 0 degrees. A lower value indicates better “alignment”.\n\nd &lt;- pre_proc_tbl(\"2023-06-10_garagedoor-1\") \n\n\nimport numpy as np\nimport scipy.stats as ss\nfrom sklearn.metrics import mutual_info_score\n\ndef numBins(nObs, corr=None):\n    #optimal number of bins for discretization\n    if corr is None: #univariate case\n        z = (8+324*nObs+12*(36*nObs+729*nObs**2)**.5)**(1/3.)\n        b = round(z/6.+2./(3*z)+1./3)\n    else: #bivariate case\n        b = round(2**-.5*(1+(1+24*nObs/(1.-corr**2))**.5)**.5)\n    \n    return int(b)\n\ndef mutualInfor(x,y, norm=False):\n  #mutual information\n  bXY = numBins(x.shape[0], corr = np.corrcoef(x,y)[0,1])\n  cXY = np.histogram2d(x,y, bXY)[0]\n  iXY = mutual_info_score(None, None, contingency=cXY)\n  if norm:\n    hX = ss.entropy(np.histogram(x, bins)[0]) #marginal \n    hY = ss.entropy(np.histogram(y, bins)[0]) #marginal\n    iXY /= min(hX, hY) #normalized mutual information\n    \n  return iXY\n\nx = r.d['x']\nx = np.array(x)\n\ny = r.d['y']\ny = np.array(y)\n\nbins=10 # descretize sample space\n\nnmi = mutualInfor(x,y,True)\n\nd = {\"nmi\": nmi}\n\nd\n\n#&gt; {'nmi': 0.46746092071197676}\n\n\n\n\n2.3.3 Evaluate Results\nTo determine the most optimal angle, a sweep needs to be done at varying increments. Typically, this is done within a range of approximately ±10 degrees.\n\nd_long &lt;- read_csv(\"../data/mu-i_angle_swp.csv\") %&gt;%\n  pivot_longer(cols = c(\"xy\", \"yz\", \"xz\"), names_to = \"name\", values_to = \"value\")\n\npreds &lt;- list()\nfor (name_2 in unique(d_long$name)) {\n  nd &lt;- d_long |&gt; dplyr::filter(name == name_2)\n  mars_model &lt;- earth::earth(value ~ angle, data = nd, nk = 3)\n  preds[[name_2]] &lt;- mars_model |&gt; predict()\n}\n\nangles &lt;- d_long |&gt; \n  filter(name == \"xy\") |&gt; \n  pull(angle)\n\npreds_df &lt;- data.frame(name = rep(names(preds), sapply(preds, length)),\n                 value = unlist(preds), angle =  angles)\n\nd_long |&gt; \n  ggplot(aes(angle, value, col = name)) +\n  geom_point() +\n  geom_line(data = preds_df, aes(angle, value)) +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 20)) +\n  labs(x = \"Angle (deg)\", \n       y = \"Mutual Information\" ,\n       col = \"Variables\", \n       title = \"Angle Sweep Results\")\n\n\n\n\nThe curve typically follows a hinge function. In our example, it may not be appropriate to select the zero degree position, and it is recommended to re-measure the top three angles. For this instance, the sensor was positioned at a five-degree clockwise (CW) offset."
  },
  {
    "objectID": "preprocessing.html#final-results",
    "href": "preprocessing.html#final-results",
    "title": "3  Preprocessing Methods",
    "section": "6.3 Final Results",
    "text": "6.3 Final Results\n\nd_fmerg_final &lt;- d_fmerg |&gt; \n  ungroup() |&gt; \n  bind_cols(smo_prob = posterior(hmm_fit, type = \"smoothing\")[,1]) |&gt; \n  mutate(bin_hmm = ifelse(smo_prob &gt; 0.999, \"Transition\", \"Idle\")) |&gt; \n  mutate(run_idle_id = consecutive_id(bin_hmm)) |&gt; \n  group_by(run_idle_id) |&gt; \n  mutate(numbers = n(),\n         bin_hmm = ifelse(n() &lt; 2000 , \"Transition\", bin_hmm)) |&gt; \n  mutate(recipe_step = paste(bin_hmm, bin))\n\n\nd_fmerg_final |&gt;\n  pivot_longer(c(x, y, z)) |&gt;\n  ggplot(aes(time, value, col = as.factor(recipe_step))) +\n  geom_point(size = 0.3) +\n  facet_wrap(~name) +\n  labs(x = \"time (s)\",\n       y = \"Acceleration (g)\",\n       col = \"Recipe Step\")\n\n\n\n\nThe unwinding the torsion coil (pink, door going up) generates a distinct signature compared to the opposite direction (green, door coming down).\nThe shape of the signal comes from a constant rate of tilt around the corner track, which lead to exponentially decaying or growing solutions, consistent with the above signal.\nThe tilt of the garage door, denoted by ((t)) can be expressed by a the following first order differential equation:\n\\[\n\\frac{d\\theta}{dt} = f(\\theta, G, t)\\\n\\]\nwhere (f(, G, t)) represents the function describing the dynamics of the garage door, and G is the geometry of the system.\nFor the simplest case of tilting about the origin (ignoring the geometry),\n\\[\n\\frac{d\\theta}{dt} =\\dot{\\theta}\\ = \\theta\n\\] the solution is:\n\\[\n\\theta \\ =  e^t\n\\]"
  },
  {
    "objectID": "datacollection.html#make-a-connection",
    "href": "datacollection.html#make-a-connection",
    "title": "5  Query Data",
    "section": "5.1 Make a Connection",
    "text": "5.1 Make a Connection\n\ncon &lt;- dbConnect(\n  RPostgres::Postgres(),\n  dbname = \"gd_phm_status\",\n  host = Sys.getenv(\"gd_db_host\"),\n  port = 5432,\n  user = Sys.getenv(\"gd_db_user\"),\n  password = Sys.getenv(\"gd_db_pw\")\n)"
  },
  {
    "objectID": "datacollection.html#get-relevant-table-names",
    "href": "datacollection.html#get-relevant-table-names",
    "title": "5  Query Data",
    "section": "5.2 Get Relevant Table Names",
    "text": "5.2 Get Relevant Table Names\n\ntbl &lt;- DBI::dbGetQuery(\n  conn = con,\n  \"SELECT table_name\n  FROM information_schema.tables\n  WHERE table_name like '%gd%'\n\"\n)\n\ntbl |&gt; pull(table_name) |&gt; cat(sep = \", \")\n\n#&gt; gd_meas_tbl, gd_config_hw_tbl, gd_config_models_tbl"
  },
  {
    "objectID": "datacollection.html#pull-data",
    "href": "datacollection.html#pull-data",
    "title": "5  Query Data",
    "section": "5.3 Pull Data",
    "text": "5.3 Pull Data\n\ntbl &lt;- DBI::dbGetQuery(\n  conn = con,\n  \n  \"WITH joined_tbl AS (\n    SELECT\n      gd_config_hw_tbl.*,\n      meas_date,\n      meas_seq,\n      status,\n      gd_meas_tbl.model AS model,\n      prob,\n      model_version,\n      version_from,\n      version_to\n    FROM gd_config_hw_tbl\n    INNER JOIN gd_meas_tbl\n      ON (gd_config_hw_tbl.location_id = gd_meas_tbl.location_id)\n    INNER JOIN gd_config_models_tbl\n      ON (\n        gd_config_hw_tbl.location_id = gd_config_models_tbl.location_id AND\n        gd_meas_tbl.model = gd_config_models_tbl.model\n         )\n    )\n  \n  SELECT\n    state,\n    city_code,\n    location_id,\n    model,\n    model_version,\n    meas_date,\n    MAX(prob) AS prob_max\n  FROM joined_tbl\n  WHERE (meas_date &gt;= version_from AND ((version_to IS NULL) OR meas_date &lt;= version_to))\n  GROUP BY state, city_code, location_id, model, model_version, meas_date;\"\n)\n\ntbl |&gt; head(10)\n\n#&gt;    state city_code location_id    model model_version  meas_date  prob_max\n#&gt; 1     MN       AAA      A00.01 arm_brkt    2023.03.12 2023-03-12 0.0008547\n#&gt; 2     MN       AAA      A00.01 arm_brkt    2023.03.12 2023-03-13 0.0014096\n#&gt; 3     MN       AAA      A00.01 arm_brkt    2023.03.12 2023-03-14 0.0009876\n#&gt; 4     MN       AAA      A00.01 arm_brkt    2023.03.12 2023-03-15 0.0023421\n#&gt; 5     MN       AAA      A00.01 arm_brkt    2023.03.15 2023-03-15 0.0023421\n#&gt; 6     MN       AAA      A00.01 arm_brkt    2023.03.15 2023-03-16 0.0069242\n#&gt; 7     MN       AAA      A00.01 arm_brkt    2023.03.15 2023-03-17 0.0062839\n#&gt; 8     MN       AAA      A00.01 arm_brkt    2023.03.15 2023-03-18 0.0352436\n#&gt; 9     MN       AAA      A00.01 arm_brkt    2023.03.15 2023-03-19 0.0210955\n#&gt; 10    MN       AAA      A00.01 arm_brkt    2023.03.15 2023-03-20 0.0015077"
  },
  {
    "objectID": "datacollection.html#plot-data",
    "href": "datacollection.html#plot-data",
    "title": "5  Query Data",
    "section": "5.4 Plot Data",
    "text": "5.4 Plot Data\n\ntbl |&gt; \n  filter(meas_date &lt; as.Date(\"2023-06-11\")) |&gt; \n  mutate(model = ifelse(model == \"arm_brkt\", \"Arm Bracket Fault\", model)) |&gt; \n  ggplot(aes(meas_date, prob_max, col = model_version)) +\n  geom_point() +\n  facet_grid(location_id~ model, scales = \"free\") +\n  scale_x_date(date_breaks = \"2 weeks\") +\n  labs(\n    title = \"Daily Maximum Fault Probability for Each IoT Device Monitored Against Model Version\", \n    x = \"Date\", \n    y = \"Fault Probability\",\n    col = \"Model Version\"\n      )"
  },
  {
    "objectID": "datacollection.html#important",
    "href": "datacollection.html#important",
    "title": "5  Query Data",
    "section": "5.5 Important!",
    "text": "5.5 Important!\nPlease close the connection after you are done.\n\ndbDisconnect(con)"
  },
  {
    "objectID": "preprocessing.html#extract-torsion-coil-response",
    "href": "preprocessing.html#extract-torsion-coil-response",
    "title": "3  Preprocessing Methods",
    "section": "6.1 Extract Torsion Coil Response",
    "text": "6.1 Extract Torsion Coil Response\nI am using a machine learning method to isolate the torsion coil unwinding and winding scenarios.\n\nimport statsmodels.api as sm1\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\nfrom sklearn import linear_model, datasets\n\n# Return the t-statistic for a given parameter estimate.\ndef tValLinR(close):\n    # tValue from a linear trend\n    x = np.ones((close.shape[0], 2))\n    x[:, 1] = np.arange(close.shape[0])\n    ols = sm1.OLS(close, x).fit()\n    return ols.tvalues[1]\n\n\ndef getBinsFromTrend(molecule, close, span):\n    '''\n    Derive labels from the sign of t-value of trend line\n    output includes:\n      - t1: End time for the identified trend\n      - tVal: t-value associated with the estimated trend coefficient\n      - bin: Sign of the trend\n    The t-statistics for each tick has a different look-back window.\n\n    - idx start time in look-forward window\n    - dt1 stop time in look-forward window\n    - df1 is the look-forward window\n    - iloc ?\n    '''\n    out = pd.DataFrame(index=molecule, columns=['t1', 'tVal', 'bin', 'windowSize'])\n    hrzns = range(*span)\n    windowSize = span[1] - span[0]\n    maxWindow = span[1] - 1\n    minWindow = span[0]\n    for idx in close.index:\n        idx += maxWindow\n        if idx &gt;= len(close):\n            break\n        df_tval = pd.Series(dtype='float64')\n        iloc0 = close.index.get_loc(idx)\n        # if iloc0+max(hrzns) &gt; close.shape[0]:\n        #    continue\n        for hrzn in hrzns:\n            dt1 = close.index[iloc0 - hrzn + 1]\n            df1 = close.loc[dt1:idx]\n            df_tval.loc[dt1] = tValLinR(df1.values)  # calculates t-statistics on period\n            dt1 = df_tval.replace([-np.inf, np.inf, np.nan],\n                              0).abs().idxmax()  # get largest t-statistics calculated over span period\n\n        # print(df_tval.index[-1])\n        # print(dt1)\n        # print(abs(df_tval.values).argmax() + minWindow)\n        out.loc[idx, ['t1', 'tVal', 'bin', 'windowSize']] = df_tval.index[-1], df_tval[dt1], np.sign(df_tval[dt1]), abs(\n            df_tval.values).argmax() + minWindow  # prevent leakage\n    out['t1'] = pd.to_datetime(out['t1'])\n    out['bin'] = pd.to_numeric(out['bin'], downcast='signed')\n\n    # deal with massive t-Value outliers - they dont provide more confidence and they ruin the scatter plot\n    tValueVariance = out['tVal'].values.var()\n    tMax = 20\n    if tValueVariance &lt; tMax:\n        tMax = tValueVariance\n\n    out.loc[out['tVal'] &gt; tMax, 'tVal'] = tMax  # cutoff tValues &gt; 20\n    out.loc[out['tVal'] &lt; (-1) * tMax, 'tVal'] = (-1) * tMax  # cutoff tValues &lt; -20\n    return out.dropna(subset=['bin'])\n\n\n\nidx_range_from = 5\nidx_range_to = 10\ndf0 = pd.Series(r.ts_data)\n\nspan = [idx_range_from,idx_range_to,1] # [3,10,1] = range(3,10)\n\ndf1 = getBinsFromTrend(df0.index, df0, span) \ntValues = df1['tVal'].values\n\n\nlibrary(reticulate)\n\nd_f &lt;- py$df1 |&gt; \n  rownames_to_column(\"id\") |&gt; \n  unnest(tVal) \n\nd_fmerg &lt;- d |&gt; \n  rownames_to_column(\"id\") |&gt; \n  left_join(d_f) |&gt;\n  tidyr::fill(bin, .direction = \"downup\") |&gt; \n  mutate(id = as.numeric(id)) |&gt; \n  na.omit() |&gt; \n  mutate(run_id = consecutive_id(bin)) |&gt; \n  group_by(run_id) |&gt; \n  mutate(bin = ifelse(n() &lt; 1000, 0, bin))\n\nd_fmerg |&gt; \n  ggplot(aes(id, z, col = as.factor(bin))) +\n  geom_point(size = 0.3) +\n  labs(x = \"time (s)\", \n       y = \"Calibrated Value\", \n       col = \"Recipe Step\")\n\n\n\n\nHere is the nomenclature:\n\n0 = horizontal or vertical position\n-1 = torsion coil winding\n1 = torsion coil unwinding"
  },
  {
    "objectID": "preprocessing.html#extract-door-idle-response",
    "href": "preprocessing.html#extract-door-idle-response",
    "title": "3  Preprocessing Methods",
    "section": "6.2 Extract Door Idle Response",
    "text": "6.2 Extract Door Idle Response\nTo extract information about whether the door is idle up or down, a simple dependent mixture model is used.\n\nlibrary(depmixS4)\n\nset.seed(123)\n\nhmm_model &lt;- depmixS4::depmix(data = d_fmerg, nstates = 2, y_smo~y)\nhmm_fit &lt;- fit(hmm_model)\n\n#&gt; converged at iteration 21 with logLik: 40562\n\n# hmm_fit@transition\n\n# plot(ts(posterior(hmm_fit, type = \"smoothing\")), ylab = \"probability\", frame = FALSE)"
  },
  {
    "objectID": "model_arm_brkt.html",
    "href": "model_arm_brkt.html",
    "title": "3  Arm Bracket Fault Detection",
    "section": "",
    "text": "4 Hilbert Huang Transform\n\nget_imf_energies &lt;- function(tbl, measurement_function = \"x\") {\n  sig &lt;- tbl %&gt;% pull({{ measurement_function }})\n  tt &lt;- tbl %&gt;% pull(new_sensor_dt)\n  \n  inputimfs &lt;-  Sig2IMF(sig, tt, max.imf = 3)$imf # note max IMF \n  n_cols &lt;- ncol(inputimfs)\n  n_rows &lt;- nrow(inputimfs)\n  if (is.null(n_cols)) return(tibble())\n  # mse_hilbert = sum(inputimfs[,1]^2)/n_rows\n  # ek = NULL\n  # for (i in 1:n_cols) ek &lt;- c(ek, mse_hilbert*2.01^(-i)/0.719) # https://link.springer.com/chapter/10.1007/978-3-030-89010-0_8\n  #\n  \n  # sample_ek = NULL\n  # for (i in 1:n_cols) sample_ek &lt;- c(sample_ek, sum(inputimfs[,i]^2)/n_rows)\n  \n  sample_ek &lt;- apply(inputimfs, 2, function(x){sum(x^2)/n_rows})\n  \n  tibble(n = 1:n_cols \n         # \"ek\" = ek\n  ) %&gt;% \n    mutate(\n      log_eek = log(sample_ek)/log(2)\n    ) %&gt;% \n    return()\n}\n\n\nget_mm_results &lt;- function(tf_object_tool, measurement_function) {\n  .create_objects_for_model &lt;- function(tf_object_tool, measurement_function) {\n    tf_object_tool &lt;- tf_object_tool %&gt;%\n      unnest(gi) %&gt;% \n      ungroup()\n    \n    tf_object_tool &lt;- tf_object_tool %&gt;% \n      unnest(str_glue(\"ie_{measurement_function}\")) %&gt;% \n      select(id, recipe_step_start, n, log_eek, {{ measurement_function }}) %&gt;%\n      filter(n() &gt;= 2) %&gt;% \n      pivot_wider(values_from = log_eek, names_from = n) %&gt;%\n      drop_na(`1`, `2`)\n      \n      fml = str_glue(\"{measurement_function} ~ `2`\") %&gt;% formula()\n      \n      list(tf_object_tool = tf_object_tool, fml = fml)\n  } \n  \n  .create_mm_model &lt;- function(model_objects) {\n    n &lt;- labels(terms(model_objects$fml)) %&gt;% length() \n    \n    ms_ols_model &lt;- lm(formula = model_objects$fml,\n                       data  = model_objects$tf_object_tool) \n    \n    ms_model &lt;- msmFit(ms_ols_model,\n                       k = 2,\n                       p = 0,\n                       sw = rep(TRUE, n + 2), \n                       control = list(trace = FALSE, parallelization = TRUE))\n  }\n  \n  .process_mm_model &lt;- function(model_objects, ms_model, measurement_function) {\n    smoTransMatrob &lt;- model_objects$tf_object_tool %&gt;%  \n      select(id, recipe_step_start, {{ measurement_function }}) %&gt;% add_row(id = NA,  .before = 1) %&gt;%\n      cbind(. ,ms_model@Fit@smoProb)\n    \n    fault_regime &lt;- get_fault_regime(smoTransMatrob, measurement_function)\n    \n    list(smoTransMatrob = smoTransMatrob,\n         smoTransMat = ms_model@Fit@smoTransMat, \n         k = ms_model@k, \n         fault_regime = fault_regime)\n  }\n  \n  model_objects &lt;- .create_objects_for_model(tf_object_tool, measurement_function)\n  ms_model &lt;- .create_mm_model(model_objects)\n  \n  .process_mm_model(model_objects, ms_model, measurement_function)\n}\n\n\nget_model_with_status &lt;- function(location_id, \n                                  model_code,\n                                  print_error = TRUE,\n                                  model = \"mm_arm_brkt\",\n                                  object = \"smoTransMatrob\") {\n  \n  .print_err &lt;- function(message = \"Error\", print_error = TRUE){\n    if (print_error) print(str_glue(\"{message} in {location_id}\")) \n    return(NULL) \n  }\n  \n  models_tool %&gt;%\n    pull({{ model }}) %&gt;% \n    pluck(1, object) %||% .print_err(print_error = print_error)\n}\n\n\nmodel_status_definitions &lt;- function(type) {\n  switch(type,\n         \"named list\" = NA, # success\n         \"list\" = NA, # missing in configuration\n         \"lgl\" = \"Error\" # processing error\n  )\n}\n\n\nget_fault_regime &lt;- function(smoTransMatrob, measurement_function = \"x\" ) {\n  regime_corr &lt;- smoTransMatrob %&gt;% \n    select({{ measurement_function }}, `1`, `2`) %&gt;% \n    round(5) %&gt;% \n    cor(use = \"complete.obs\")\n  \n  which.max(regime_corr[1, 2:3]) \n}\n\n\nget_model_fails &lt;- function(path, location_id, prob_threshold, daysback, model, measurement_function, faults_only = TRUE) {\n  subset_dummy &lt;- list()\n  \n  for (location_id in location_ids) {\n    \n    models_tool &lt;- readRDS(file = str_glue(\"{path}/models/model_object_{location_id}.rds\")) \n    \n    smoTransMatrob &lt;- get_model_with_status(location_id,\n                                            models_tool,\n                                            print_error = FALSE, \n                                            model = str_glue(\"mm_{model}_{measurement_function}\"),\n                                            object = \"smoTransMatrob\") %||% next\n    fault_regime &lt;- get_model_with_status(location_id,\n                                          models_tool,\n                                          print_error = FALSE, \n                                          model = str_glue(\"mm_{model}_{measurement_function}\"),\n                                          object = \"fault_regime\") %||% next\n    \n    smoTransMatrob &lt;- smoTransMatrob %&gt;% \n      mutate(tool_name = location_id,\n             fault_probability =!!as.symbol(fault_regime), \n             fault_probability = round(fault_probability, 5)) %&gt;% \n      filter(recipe_step_start &gt; Sys.Date() - daysback)\n    \n    if (faults_only) {\n      smoTransMatrob &lt;- smoTransMatrob %&gt;% filter(fault_probability &gt;= {{ prob_threshold }})  \n    }\n    \n    subset_dummy[[location_id]] &lt;- smoTransMatrob %&gt;% \n      select(tool_name, id, {{ measurement_function }}, recipe_step_start, fault_probability)\n    \n  }\n  \n  do.call(rbind, subset_dummy) %&gt;% remove_rownames() \n}\n\n\nretrieve_model_objects &lt;- function(path, location_id, model, measurement_function) {\n  \n  models_tool &lt;- readRDS(file = str_glue(\"{path}/models/model_object_{location_id}.rds\")) \n  \n  smoTransMatrob &lt;- get_model_with_status(location_id,\n                                          models_tool,\n                                          print_error = FALSE, \n                                          model = str_glue(\"mm_{model}_{measurement_function}\"), \n                                          object = \"smoTransMatrob\")\n  smoTransMat &lt;- get_model_with_status(location_id,\n                                       models_tool, \n                                       print_error = FALSE, \n                                       model = str_glue(\"mm_{model}_{measurement_function}\"),\n                                       object = \"smoTransMat\")\n  fault_regime &lt;- get_model_with_status(location_id,\n                                        models_tool,\n                                        print_error = FALSE, \n                                        model = str_glue(\"mm_{model}_{measurement_function}\"),\n                                        object = \"fault_regime\")\n  k &lt;- get_model_with_status(location_id,\n                             models_tool,\n                             print_error = FALSE, \n                             model = str_glue(\"mm_{model}_{measurement_function}\"),\n                             object = \"k\")\n  \n  list(smoTransMatrob = smoTransMatrob,\n       smoTransMat = smoTransMat, \n       k = k, \n       fault_regime = fault_regime)\n}\n\n\ncalculate_transition_matrix &lt;- function(path, location_id, model, measurement_function, t_steps = 1L) {\n  model_objects &lt;- retrieve_model_objects(path, location_id, model, measurement_function)\n  \n  smoTransMatrob &lt;- model_objects$smoTransMatrob %&gt;% select(`1`, `2`) \n  smoTransMat &lt;- model_objects$smoTransMat\n  k &lt;- model_objects$k\n  fault_regime &lt;- model_objects$fault_regime\n  \n  gamma_t_s &lt;- matrix(apply(matrix(unlist(smoTransMat),nrow = k*k),1,sum)/rep(apply(smoTransMatrob[-1,],2,sum),rep(k,k)),ncol = k)\n  dimnames(gamma_t_s) &lt;- switch(fault_regime, \"1\" = rep(list(c(\"Fault\", \"Stable\")),2), \"2\" = rep(list(c(\"Stable\", \"Fault\")),2))\n  \n  if (t_steps &lt;= 2) return(gamma_t_s)\n  \n  gamma_t &lt;- matrix(apply(matrix(unlist(smoTransMat[1:t_steps]),nrow = k*k),1,sum)/rep(apply(head(smoTransMatrob[-1,], t_steps),2,sum),rep(k,k)),ncol = k)\n  \n  gamma_s &lt;- gamma_t_s %*% MASS::ginv(gamma_t)\n  gamma_s &lt;- abs(kronecker(gamma_s, k-1)) # This should hold true for MP invertibility\n  gamma_s &lt;- t(t(gamma_s) / apply(gamma_s, 2, sum))\n  dimnames(gamma_s) &lt;- switch(fault_regime, \"1\" = rep(list(c(\"Fault\", \"Stable\")),2), \"2\" = rep(list(c(\"Stable\", \"Fault\")),2))\n  \n  .check_topological_mapping &lt;- function(gamma_s) {\n    evec &lt;- eigen(gamma_s)$vectors\n    t(evec[, 1]) %*% evec[, 2] &lt;= abs(evec[, 1]) %*% abs(evec[, 2])\n  }\n  \n  .check_statdist &lt;- function(gamma_x) {\n    m &lt;- dim(gamma_x)[1]\n    stat_dist &lt;- matrix(1, 1, m) %*% solve(diag(1, m) - gamma_x + matrix(1, m, m))\n    \n    all.equal(eigen(gamma_x)$values, as.vector(stat_dist)) &lt; sqrt(.Machine$double.eps)\n  }\n  \n  if (!.check_topological_mapping(gamma_s) | .check_statdist(gamma_s)) return(gamma_t_s)\n  \n  gamma_s\n}\n\n\nfilter_fault_freq &lt;- function(tbl, number_of_fails) {\n  tbl %&gt;%   \n    mutate(number_of_fails = n()) %&gt;% \n    filter(number_of_fails &gt;=!!number_of_fails) \n}\n\nfilter_fault_freq_group &lt;- function(tbl, groups = c(\"fac\", \"tool_name\"), number_of_fails) {\n  tbl %&gt;%\n    group_by(across(all_of(groups))) %&gt;% \n    filter_fault_freq(number_of_fails) %&gt;%\n    distinct(across(all_of(groups)))\n}"
  },
  {
    "objectID": "model_arm_brkt.html#hilbert-huang-transform",
    "href": "model_arm_brkt.html#hilbert-huang-transform",
    "title": "4  Arm Bracket Fault Detection",
    "section": "4.1 Hilbert Huang Transform",
    "text": "4.1 Hilbert Huang Transform\n\nimf_ener &lt;- function(tbl, meas_fn = \"x\") {\n  sig &lt;- tbl %&gt;% pull({{ meas_fn }})\n  tt &lt;- tbl %&gt;% pull(new_sensor_dt)\n  \n  inputimfs &lt;-  Sig2IMF(sig, tt, max.imf = 3)$imf # note max IMF \n  n_cols &lt;- ncol(inputimfs)\n  n_rows &lt;- nrow(inputimfs)\n  if (is.null(n_cols)) return(tibble())\n  # mse_hilbert = sum(inputimfs[,1]^2)/n_rows\n  # ek = NULL\n  # for (i in 1:n_cols) ek &lt;- c(ek, mse_hilbert*2.01^(-i)/0.719) # https://link.springer.com/chapter/10.1007/978-3-030-89010-0_8\n  #\n  \n  # sample_ek = NULL\n  # for (i in 1:n_cols) sample_ek &lt;- c(sample_ek, sum(inputimfs[,i]^2)/n_rows)\n  \n  sample_ek &lt;- apply(inputimfs, 2, function(x){sum(x^2)/n_rows})\n  \n  tibble(n = 1:n_cols \n         # \"ek\" = ek\n  ) %&gt;% \n    mutate(\n      log_eek = log(sample_ek)/log(2)\n    ) %&gt;% \n    return()\n}"
  },
  {
    "objectID": "model_arm_brkt.html#fit-hmm",
    "href": "model_arm_brkt.html#fit-hmm",
    "title": "4  Arm Bracket Fault Detection",
    "section": "4.2 Fit HMM",
    "text": "4.2 Fit HMM\n\nget_mm_results &lt;- function(tf_loc_id, meas_fn) {\n  .create_objects_for_model &lt;- function(tf_loc_id, meas_fn) {\n    tf_loc_id &lt;- tf_loc_id %&gt;%\n      unnest(gi) %&gt;% \n      ungroup()\n    \n    tf_loc_id &lt;- tf_loc_id %&gt;% \n      unnest(str_glue(\"ie_{meas_fn}\")) %&gt;% \n      select(id, rs_start, n, log_eek, {{ meas_fn }}) %&gt;%\n      filter(n() &gt;= 2) %&gt;% \n      pivot_wider(values_from = log_eek, names_from = n) %&gt;%\n      drop_na(`1`, `2`)\n      \n      fml = str_glue(\"{meas_fn} ~ `2`\") %&gt;% formula()\n      \n      list(tf_loc_id = tf_loc_id, fml = fml)\n  } \n  \n  .create_mm_model &lt;- function(model_obj) {\n    n &lt;- labels(terms(model_obj$fml)) %&gt;% length() \n    \n    ms_ols_model &lt;- lm(formula = model_obj$fml,\n                       data  = model_obj$tf_loc_id) \n    \n    ms_model &lt;- msmFit(ms_ols_model,\n                       k = 2,\n                       p = 0,\n                       sw = rep(TRUE, n + 2), \n                       control = list(trace = FALSE, parallelization = TRUE))\n  }\n  \n  .process_mm_model &lt;- function(model_obj, ms_model, meas_fn) {\n    smoTransMatrob &lt;- model_obj$tf_loc_id %&gt;%  \n      select(id, rs_start, {{ meas_fn }}) %&gt;% add_row(id = NA,  .before = 1) %&gt;%\n      cbind(. ,ms_model@Fit@smoProb)\n    \n    fault_regime &lt;- get_fault_regime(smoTransMatrob, meas_fn)\n    \n    list(smoTransMatrob = smoTransMatrob,\n         smoTransMat = ms_model@Fit@smoTransMat, \n         k = ms_model@k, \n         fault_regime = fault_regime)\n  }\n  \n  model_obj &lt;- .create_objects_for_model(tf_loc_id, meas_fn)\n  ms_model &lt;- .create_mm_model(model_obj)\n  \n  .process_mm_model(model_obj, ms_model, meas_fn)\n}\n\n\nget_model_status &lt;- function(loc_id, \n                                  model_code,\n                                  print_error = TRUE,\n                                  model = \"mm_arm_brkt\",\n                                  object = \"smoTransMatrob\") {\n  \n  .print_err &lt;- function(message = \"Error\", print_error = TRUE){\n    if (print_error) print(str_glue(\"{message} in {loc_id}\")) \n    return(NULL) \n  }\n  \n  models_tool %&gt;%\n    pull({{ model }}) %&gt;% \n    pluck(1, object) %||% .print_err(print_error = print_error)\n}\n\n\nmodel_status_defs &lt;- function(type) {\n  switch(type,\n         \"named list\" = NA, # success\n         \"list\" = NA, # missing in configuration\n         \"lgl\" = \"Error\" # processing error\n  )\n}\n\n\nget_fault_regime &lt;- function(smoTransMatrob, meas_fn = \"x\" ) {\n  regime_corr &lt;- smoTransMatrob %&gt;% \n    select({{ meas_fn }}, `1`, `2`) %&gt;% \n    round(5) %&gt;% \n    cor(use = \"complete.obs\")\n  \n  which.max(regime_corr[1, 2:3]) \n}\n\n\nget_model_fails &lt;- function(path, loc_id, prob_thres, daysback, model, meas_fn, faults_only = TRUE) {\n  subset_dummy &lt;- list()\n  \n  for (loc_id in loc_ids) {\n    \n    models_tool &lt;- readRDS(file = str_glue(\"{path}/models/model_object_{loc_id}.rds\")) \n    \n    smoTransMatrob &lt;- get_model_status(loc_id,\n                                            models_tool,\n                                            print_error = FALSE, \n                                            model = str_glue(\"mm_{model}_{meas_fn}\"),\n                                            object = \"smoTransMatrob\") %||% next\n    fault_regime &lt;- get_model_status(loc_id,\n                                          models_tool,\n                                          print_error = FALSE, \n                                          model = str_glue(\"mm_{model}_{meas_fn}\"),\n                                          object = \"fault_regime\") %||% next\n    \n    smoTransMatrob &lt;- smoTransMatrob %&gt;% \n      mutate(tool_name = loc_id,\n             fault_prob =!!as.symbol(fault_regime), \n             fault_prob = round(fault_prob, 5)) %&gt;% \n      filter(rs_start &gt; Sys.Date() - daysback)\n    \n    if (faults_only) {\n      smoTransMatrob &lt;- smoTransMatrob %&gt;% filter(fault_prob &gt;= {{ prob_thres }})  \n    }\n    \n    subset_dummy[[loc_id]] &lt;- smoTransMatrob %&gt;% \n      select(tool_name, id, {{ meas_fn }}, rs_start, fault_prob)\n    \n  }\n  \n  do.call(rbind, subset_dummy) %&gt;% remove_rownames() \n}"
  },
  {
    "objectID": "model_arm_brkt.html#evaluate-fit",
    "href": "model_arm_brkt.html#evaluate-fit",
    "title": "4  Arm Bracket Fault Detection",
    "section": "4.3 Evaluate Fit",
    "text": "4.3 Evaluate Fit\n\nretrieve_model_obj &lt;- function(path, loc_id, model, meas_fn) {\n  \n  models_tool &lt;- readRDS(file = str_glue(\"{path}/models/model_object_{loc_id}.rds\")) \n  \n  smoTransMatrob &lt;- get_model_status(loc_id,\n                                          models_tool,\n                                          print_error = FALSE, \n                                          model = str_glue(\"mm_{model}_{meas_fn}\"), \n                                          object = \"smoTransMatrob\")\n  smoTransMat &lt;- get_model_status(loc_id,\n                                       models_tool, \n                                       print_error = FALSE, \n                                       model = str_glue(\"mm_{model}_{meas_fn}\"),\n                                       object = \"smoTransMat\")\n  fault_regime &lt;- get_model_status(loc_id,\n                                        models_tool,\n                                        print_error = FALSE, \n                                        model = str_glue(\"mm_{model}_{meas_fn}\"),\n                                        object = \"fault_regime\")\n  k &lt;- get_model_status(loc_id,\n                             models_tool,\n                             print_error = FALSE, \n                             model = str_glue(\"mm_{model}_{meas_fn}\"),\n                             object = \"k\")\n  \n  list(smoTransMatrob = smoTransMatrob,\n       smoTransMat = smoTransMat, \n       k = k, \n       fault_regime = fault_regime)\n}\n\n\nfilter_fault_freq &lt;- function(tbl, number_of_fails) {\n  tbl %&gt;%   \n    mutate(number_of_fails = n()) %&gt;% \n    filter(number_of_fails &gt;=!!number_of_fails) \n}\n\nfilter_fault_freq_group &lt;- function(tbl, groups = c(\"fac\", \"tool_name\"), number_of_fails) {\n  tbl %&gt;%\n    group_by(across(all_of(groups))) %&gt;% \n    filter_fault_freq(number_of_fails) %&gt;%\n    distinct(across(all_of(groups)))\n}"
  },
  {
    "objectID": "model_arm_brkt.html#chapman-kolmogorov",
    "href": "model_arm_brkt.html#chapman-kolmogorov",
    "title": "4  Arm Bracket Fault Detection",
    "section": "4.4 Chapman-Kolmogorov",
    "text": "4.4 Chapman-Kolmogorov\n\ncalc_trans_mat &lt;- function(path, loc_id, model, meas_fn, t_steps = 1L) {\n  model_obj &lt;- retrieve_model_obj(path, loc_id, model, meas_fn)\n  \n  smoTransMatrob &lt;- model_obj$smoTransMatrob %&gt;% select(`1`, `2`) \n  smoTransMat &lt;- model_obj$smoTransMat\n  k &lt;- model_obj$k\n  fault_regime &lt;- model_obj$fault_regime\n  \n  gamma_t_s &lt;- matrix(apply(matrix(unlist(smoTransMat),nrow = k*k),1,sum)/rep(apply(smoTransMatrob[-1,],2,sum),rep(k,k)),ncol = k)\n  dimnames(gamma_t_s) &lt;- switch(fault_regime, \"1\" = rep(list(c(\"Fault\", \"Stable\")),2), \"2\" = rep(list(c(\"Stable\", \"Fault\")),2))\n  \n  if (t_steps &lt;= 2) return(gamma_t_s)\n  \n  gamma_t &lt;- matrix(apply(matrix(unlist(smoTransMat[1:t_steps]),nrow = k*k),1,sum)/rep(apply(head(smoTransMatrob[-1,], t_steps),2,sum),rep(k,k)),ncol = k)\n  \n  gamma_s &lt;- gamma_t_s %*% MASS::ginv(gamma_t)\n  gamma_s &lt;- abs(kronecker(gamma_s, k-1)) # This should hold true for MP invertibility\n  gamma_s &lt;- t(t(gamma_s) / apply(gamma_s, 2, sum))\n  dimnames(gamma_s) &lt;- switch(fault_regime, \"1\" = rep(list(c(\"Fault\", \"Stable\")),2), \"2\" = rep(list(c(\"Stable\", \"Fault\")),2))\n  \n  .check_topmap &lt;- function(gamma_s) {\n    evec &lt;- eigen(gamma_s)$vectors\n    t(evec[, 1]) %*% evec[, 2] &lt;= abs(evec[, 1]) %*% abs(evec[, 2])\n  }\n  \n  .check_statdist &lt;- function(gamma_x) {\n    m &lt;- dim(gamma_x)[1]\n    stat_dist &lt;- matrix(1, 1, m) %*% solve(diag(1, m) - gamma_x + matrix(1, m, m))\n    \n    all.equal(eigen(gamma_x)$values, as.vector(stat_dist)) &lt; sqrt(.Machine$double.eps)\n  }\n  \n  if (!.check_topmap(gamma_s) | .check_statdist(gamma_s)) return(gamma_t_s)\n  \n  gamma_s\n}"
  },
  {
    "objectID": "bom.html",
    "href": "bom.html",
    "title": "1  Bill of Materials",
    "section": "",
    "text": "Each installation has its own BOM structure report.\nColumn definitions:\n\nLv: The hardware level, which can expand to multiple monitoring systems if needed.\nComponent: Serial number to be scanned if needed.\nSeq: The operation sequence from installation onward.\nDescription: Description of the part or component.\nQuantity per: Number of parts needed for functionality.\nFix: Repairability of parts.\nOn-date: Used to track stable parts. Default to “Prepared” date on top.\nOff-date: Used to track depreciated parts. NULL if stable.\nRev: Revision to track prints and schematics.\nUnit Cost: Cost at the time of document.\nVendor: Purchase location.\nVendor PN: Vendor part number.\n\n\nfile_list &lt;- list.files(\"../BOM/\", pattern = \"BOM STRUCTURE REPORT – ALL LEVELS\", full.names = TRUE)\n\nbom_data &lt;- data.frame()\n\nfor (filename in file_list) {\n  location_id &lt;- stringr::str_extract(filename, \"[A-Z]\\\\d{2}\\\\.\\\\d{2}(?=\\\\.xlsx$)\")\n  \n  data &lt;- read_xlsx(filename, skip = 6) |&gt;\n    select(-matches(\"^\\\\.\\\\.\")) |&gt; \n    mutate(location_id = location_id) \n  \n  bom_data &lt;- bind_rows(bom_data, data)\n}\n\nbom_data &lt;- bom_data |&gt; relocate(location_id) \n\nbom_data |&gt; filter(location_id == \"A00.01\")\n\n#&gt;    location_id Lv Component    Seq                         Description Quantity Fix\n#&gt; 1       A00.01 01   GD-0001 000001                 AD335 Accelerometer        1   N\n#&gt; 2       A00.01 01   GD-0003 000001          Arduino Uno WiFi R3, Board        1   N\n#&gt; 3       A00.01 01   GD-0004 000002            Cable, USB- Printer 1 ft        1   N\n#&gt; 4       A00.01 01   GD-0005 000001        Breadboard Jumper M-F ribbon        1   Y\n#&gt; 5       A00.01 02   GD-0006 000001                Cable, USB M-F 10 ft        1   N\n#&gt; 6       A00.01 01   GD-0007 000002               Extension cord, 15 ft        1   N\n#&gt; 7       A00.01 01   GD-0008 000001 Arduino Uno WiFi R3, Case, 3D print        1   Y\n#&gt; 8       A00.01 01   GD-0009 000001                    ADXL Mount, 2pcs        1   Y\n#&gt; 9       A00.01 01   GD-0010 000002                     Dell Wyse, 3040        1   Y\n#&gt; 10      A00.01 01   GD-0011 000002                  500GB M.2. Crucial        1   N\n#&gt; 11      A00.01 01   GD-0012 000001      SCREW, M2 x  4.8 mm LG, BLK OX        2   N\n#&gt; 12      A00.01 01   GD-0013 000001       SCREW, M3 x  20 mm LG, BLK OX        4   N\n#&gt;    On-date Off-date Rev Unit Cost   Vendor    Vendor PN\n#&gt; 1       NA       NA   A     14.95 adafruit 1528-1120-ND\n#&gt; 2       NA       NA   A     27.60  Digikey 1050-1024-ND\n#&gt; 3       NA       NA   A      4.99   Amazon   B08LDRMFCB\n#&gt; 4       NA       NA   A      3.95  Digikey 1528-1162-ND\n#&gt; 5       NA       NA   A      8.59   Amazon   B08FJ8Z4TJ\n#&gt; 6       NA       NA   A      7.95   Amazon   B000KKJUHE\n#&gt; 7       NA       NA   A      &lt;NA&gt;     &lt;NA&gt;         &lt;NA&gt;\n#&gt; 8       NA       NA   A      &lt;NA&gt;     &lt;NA&gt;         &lt;NA&gt;\n#&gt; 9       NA       NA   A     35.23     ebay         &lt;NA&gt;\n#&gt; 10      NA       NA   A     21.99   Amazon  CT500P3SSD8\n#&gt; 11      NA       NA   A      &lt;NA&gt;     ebay         &lt;NA&gt;\n#&gt; 12      NA       NA   A      &lt;NA&gt;     ebay         &lt;NA&gt;\n\n\nThe total cost per installation:\n\nbom_data &lt;- bom_data |&gt; \n  clean_names() |&gt; \n  mutate(unit_cost = parse_number(unit_cost))\n\nbom_data |&gt;\n  group_by(location_id) |&gt;\n  summarize(total_cost = sum(unit_cost, na.rm = T))\n\n#&gt; # A tibble: 3 × 2\n#&gt;   location_id total_cost\n#&gt;   &lt;chr&gt;            &lt;dbl&gt;\n#&gt; 1 A00.01            125.\n#&gt; 2 B00.01            125.\n#&gt; 3 C00.01            125.\n\n\nWe can also plot the parts installed.\n\nbom_data |&gt; \n  group_by(location_id, component, description) |&gt; \n  count() |&gt; \n  ggplot(aes(component, n, fill = location_id)) +\n  geom_col() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))\n\n\n\n\nIf there are any one offs, you could filter through the original table using the serial number to track parts."
  }
]